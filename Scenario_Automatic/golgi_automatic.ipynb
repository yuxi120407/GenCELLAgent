{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a6756e-dfc1-4876-a1ea-a138ed064d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import asyncio\n",
    "import datetime\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import sys\n",
    "sys.path.append('/home/idies/workspace/Storage/xyu1/persistent/GenCELLAgent/')\n",
    "\n",
    "from src.tools.serp import search as google_search_summary\n",
    "from src.tools.segment import segment_image \n",
    "from src.tools.segmentation_eval import segmentation_evaluator\n",
    "from src.tools.oneshot_segGPT import seggpt_inference_img\n",
    "from src.tools.mitonet import mitonet_inference\n",
    "from src.tools.summarizer import summarizer_report\n",
    "from src.tools.launch_human_correction import launch_sam_correction_tool\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bdc627-a02f-49d7-af2e-8fd81d530cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_iou(pred_mask, gt_mask):\n",
    "    pred = np.array(pred_mask) > 0\n",
    "    gt = np.array(gt_mask) > 0\n",
    "\n",
    "    intersection = np.logical_and(pred, gt).sum()\n",
    "    union = np.logical_or(pred, gt).sum()\n",
    "\n",
    "    if union == 0:\n",
    "        return 1.0 if intersection == 0 else 0.0  # handle empty masks\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "def get_score(outputs_second):\n",
    "    evaluation_data = outputs_second.get(\"evaluation\", {})\n",
    "    score_second = None\n",
    "\n",
    "    # Case 1: If evaluation_data is a dict with raw text fallback\n",
    "    if isinstance(evaluation_data, dict):\n",
    "        raw_text_second = evaluation_data.get(\"raw_text\", \"\")\n",
    "        cleaned_json_second = raw_text_second.strip('`').strip()\n",
    "\n",
    "        # Remove \"json\" prefix if present\n",
    "        if cleaned_json_second.startswith(\"json\"):\n",
    "            cleaned_json_second = cleaned_json_second[len(\"json\"):].strip()\n",
    "\n",
    "    # Case 2: If evaluation_data is just a string (raw JSON)\n",
    "    elif isinstance(evaluation_data, str):\n",
    "        cleaned_json_second = json.dumps(evaluation_data, indent=2)\n",
    "    else:\n",
    "        cleaned_json_second = \"\"\n",
    "\n",
    "    # Try to find OverallScore in the cleaned text\n",
    "    match_second = re.search(r'\"OverallScore\"\\s*:\\s*(\\d+\\.?\\d*)', cleaned_json_second)\n",
    "    if match_second:\n",
    "        score_str_second = match_second.group(1)\n",
    "        score_second = float(score_str_second)\n",
    "    else:\n",
    "        print(\"OverallScore not found in evaluation data.\")\n",
    "    return score_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c32034-529b-48ab-ade7-bfd23b7fffa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_filename = \"golgi_apparatus_visual_characteristics.json\"\n",
    "\n",
    "# Read the file\n",
    "with open(input_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Now you can use `data` like a regular Python dictionary\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b7001-682e-435c-9d56-e026d1fce84d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_dict = json.loads(data)\n",
    "\n",
    "# Now extract the segmentation prompt\n",
    "segmentation_prompt = result_dict[\"summary\"][\"segmentation_prompt\"]\n",
    "visual_characteristics = result_dict[\"summary\"][\"visual_characteristics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62b151-fcc9-4885-b7ce-2e3518eb4be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "#[15,25,33,37,53,65,82,89,9,97]\n",
    "\n",
    "for index in [25]:\n",
    "    for test in range(1):\n",
    "        # Create a timestamped directory for the current run\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        save_dir = f\"./results_golgi/best_per_step_Gemini_2_5_init_new_ICT_{index}/run_{timestamp}\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Setup\n",
    "        base_img_path = \"/home/idies/workspace/Storage/xyu1/persistent/Langchain/ours_test/test_images/golgi/images/image_{}.png\"\n",
    "        base_label_path = \"/home/idies/workspace/Storage/xyu1/persistent/Langchain/ours_test/test_images/golgi/labels/label_{}.png\"\n",
    "        segment_save_path = \"/home/idies/workspace/Storage/xyu1/persistent/Langchain/ours_test/segment_resutls/results.png\"\n",
    "        segment_mask_path = \"/home/idies/workspace/Storage/xyu1/persistent/Langchain/ours_test/segment_resutls/results_mask.png\"\n",
    "\n",
    "        image_example_1_path = f\"/home/idies/workspace/Storage/xyu1/persistent/Langchain/ours_test/test_images/golgi/images/image_{index}.png\"\n",
    "        image_example_2_path = f\"/home/idies/workspace/Storage/xyu1/persistent/Langchain/ours_test/test_images/golgi/overlay_all/image_{index}.png\"\n",
    "        evaluation_prompt_path = \"in_context_prompt_golgi.json\"\n",
    "\n",
    "        init_seg_path = os.path.join(save_dir, f\"initial_segment_step_0_iter_0.png\")\n",
    "        init_mask_path = os.path.join(save_dir, f\"initial_mask_step_0_iter_0.png\")\n",
    "        init_gt_path = os.path.join(save_dir, f\"ground_truth_step_0_iter_0.png\")\n",
    "        init_prompt_path = os.path.join(save_dir, f\"initial_prompt_step_0_iter_0.txt\")\n",
    "        init_IOU_path = os.path.join(save_dir, f\"IOU_step_0_iter_0.txt\")\n",
    "\n",
    "\n",
    "        image_path = base_img_path.format(index)\n",
    "        ground_truth_path = base_label_path.format(index)\n",
    "\n",
    "        n_steps = 5\n",
    "        n_trials_per_step = 5\n",
    "\n",
    "        # Replace these with actual objects\n",
    "        current_prompt = segmentation_prompt  # make sure this is defined\n",
    "\n",
    "        all_step_results = []\n",
    "        prompt_history = []\n",
    "\n",
    "        for step in range(n_steps):\n",
    "            print(f\"\\n========== Step {step + 1} ==========\")\n",
    "\n",
    "            step_best_score = float('-inf')\n",
    "            step_best_mask = None\n",
    "            step_best_segment = None\n",
    "            step_best_prompt = current_prompt\n",
    "            step_best_ground_truth = np.array(Image.open(ground_truth_path))\n",
    "\n",
    "\n",
    "            #save_all step images\n",
    "            step_dir = os.path.join(save_dir, f\"step_{step+1}\")\n",
    "            os.makedirs(step_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "            for iteration in range(n_trials_per_step):\n",
    "                print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "                iter_dir = os.path.join(step_dir, f\"iter_{iteration+1}\")\n",
    "                os.makedirs(iter_dir, exist_ok=True)\n",
    "                \n",
    "                #1 first segment the init the image with tht init prompt\n",
    "                segment_image(current_prompt, image_path)\n",
    "\n",
    "                if step == 0 and iteration == 0:\n",
    "                    # Load images\n",
    "                    segmentation_image = Image.open(segment_save_path)\n",
    "                    mask_image = Image.open(segment_mask_path)\n",
    "                    ground_truth_label = np.array(Image.open(ground_truth_path))\n",
    "\n",
    "                    iou_score = compute_iou(mask_image, ground_truth_label)\n",
    "                    print(f\"📊 init IoU: {iou_score:.4f}\")\n",
    "\n",
    "                    # Save IoU to file\n",
    "                    with open(init_IOU_path, \"w\") as f:\n",
    "                        f.write(f\"IoU: {iou_score:.4f}\")\n",
    "\n",
    "                    #segmentation_image.save(init_seg_path)\n",
    "                    mask_image.save(init_mask_path)\n",
    "                    Image.fromarray(ground_truth_label).save(init_gt_path)\n",
    "                    segmentation_image.save(init_seg_path)\n",
    "\n",
    "                    with open(init_prompt_path, \"w\") as pf:\n",
    "                        pf.write(current_prompt)\n",
    "\n",
    "                #1 first evalautor the init image segmentation to generate the refine prompt\n",
    "                outputs_init = segmentation_evaluator(visual_characteristics, \n",
    "                                                 segment_save_path, \n",
    "                                                 current_prompt,\n",
    "                                                 evaluation_prompt_path,\n",
    "                                                 image_example_1_path,\n",
    "                                                 image_example_2_path)\n",
    "\n",
    "                refined_prompt = outputs_init[\"refined_segmentation_prompt\"]\n",
    "                \n",
    "                if step == 0:\n",
    "                    raw_text = outputs_init[\"evaluation\"].get(\"raw_text\", \"\")\n",
    "                    cleaned_json = raw_text.strip('`').strip()\n",
    "\n",
    "                    # Step 3: Remove optional \"json\" prefix if present\n",
    "                    if cleaned_json.startswith(\"json\"):\n",
    "                        cleaned_json = cleaned_json[len(\"json\"):].strip()\n",
    "\n",
    "                    match = re.search(r'\"OverallScore\"\\s*:\\s*(\\d+\\.?\\d*)', cleaned_json)\n",
    "                    if match:\n",
    "                        score_str = match.group(1) if match.group(1) is not None else match.group(2)\n",
    "                        score = float(score_str)\n",
    "                    \n",
    "                    segmentation_image.save(os.path.join(iter_dir, f\"step_0_iter_{iteration}_score_{score}.png\"))\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                #2 second segment image with refine prompt\n",
    "                segment_image(refined_prompt, image_path)\n",
    "                                            \n",
    "                                            \n",
    "                outputs_second = segmentation_evaluator(visual_characteristics, \n",
    "                                                 segment_save_path, \n",
    "                                                 refined_prompt,\n",
    "                                                 evaluation_prompt_path,\n",
    "                                                 image_example_1_path,\n",
    "                                                 image_example_2_path)\n",
    "                                            \n",
    "                                            \n",
    "                segmentation_image = Image.open(segment_save_path).copy()\n",
    "                mask_image = Image.open(segment_mask_path).convert('L').copy()\n",
    "                mask_array = np.array(mask_image, dtype=np.uint8)\n",
    "\n",
    "\n",
    "                total_pixels = mask_array.size\n",
    "                foreground_pixels = np.sum(mask_array > 0)\n",
    "                foreground_ratio = foreground_pixels / total_pixels\n",
    "\n",
    "                raw_text_second = outputs_second[\"evaluation\"].get(\"raw_text\", \"\")\n",
    "                cleaned_json_second = raw_text_second.strip('`').strip()\n",
    "\n",
    "                # Step 3: Remove optional \"json\" prefix if present\n",
    "                if cleaned_json_second.startswith(\"json\"):\n",
    "                    cleaned_json_second = cleaned_json_second[len(\"json\"):].strip()\n",
    "\n",
    "                match_second = re.search(r'\"OverallScore\"\\s*:\\s*(\\d+\\.?\\d*)', cleaned_json_second)\n",
    "                if match_second:\n",
    "                    score_str_second = match_second.group(1) if match_second.group(1) is not None else match_second.group(2)\n",
    "                    score_second = float(score_str_second)\n",
    "\n",
    "                print(f\"Foreground ratio: {foreground_ratio:.4f}, Score: {score_second:.2f}\")\n",
    "\n",
    "                mask_path = os.path.join(iter_dir, f\"mask_ratio_{foreground_ratio:.4f}_score_{score_second}.png\")\n",
    "                segment_path = os.path.join(iter_dir, f\"segment_ratio_{foreground_ratio:.4f}_score_{score_second}.png\")\n",
    "                prompt_path = os.path.join(iter_dir, f\"prompt_ratio_{foreground_ratio:.4f}_score_{score_second}.txt\")\n",
    "                review_path = os.path.join(iter_dir, f\"review_path_ratio_{foreground_ratio:.4f}_score_{score_second}.txt\")\n",
    "                mask_image.save(mask_path)\n",
    "                segmentation_image.save(segment_path)\n",
    "\n",
    "                with open(prompt_path, \"w\") as pf:\n",
    "                    pf.write(refined_prompt)\n",
    "\n",
    "                with open(review_path, \"w\", encoding=\"utf-8\") as pf:\n",
    "                    pf.write(raw_text_second)\n",
    "\n",
    "\n",
    "\n",
    "                if 0.15 <= foreground_ratio <= 0.75:\n",
    "                    if score_second > step_best_score:\n",
    "                        step_best_score = score_second\n",
    "                        step_best_mask = mask_image.copy()\n",
    "                        step_best_segment = segmentation_image.copy()\n",
    "                        step_best_prompt = refined_prompt  # track best prompt for next step\n",
    "                        print(\"✅ New best saved for this step.\")\n",
    "\n",
    "                    else:\n",
    "                        print(\"ℹ️ Meets condition but not highest score.\")\n",
    "                else:\n",
    "                    print(\"❌ Skipped due to poor foreground ratio.\")\n",
    "\n",
    "\n",
    "\n",
    "            # Use best prompt from this step for next step\n",
    "            current_prompt = step_best_prompt\n",
    "            prompt_history.append({\n",
    "                \"step\": step + 1,\n",
    "                \"used_prompt\": current_prompt\n",
    "            })\n",
    "\n",
    "            print(f\"\\n🔁 Final prompt used for Step {step + 1}:\")\n",
    "            print(current_prompt)\n",
    "\n",
    "            if step_best_mask and step_best_segment:\n",
    "                mask_path = os.path.join(save_dir, f\"best_mask_step_{step+1}_iter{iteration+1}.png\")\n",
    "                segment_path = os.path.join(save_dir, f\"best_segment_step_{step+1}_iter{iteration+1}.png\")\n",
    "                prompt_path = os.path.join(save_dir, f\"best_prompt_step_{step+1}_iter{iteration+1}.txt\")\n",
    "                iou_path = os.path.join(save_dir, f\"best_prompt_IOU_step_{step+1}_iter{iteration+1}.txt\")\n",
    "                step_best_mask.save(mask_path)\n",
    "                step_best_segment.save(segment_path)\n",
    "\n",
    "                with open(prompt_path, \"w\") as pf:\n",
    "                    pf.write(step_best_prompt)\n",
    "\n",
    "\n",
    "                iou_score = compute_iou(step_best_mask, step_best_ground_truth)\n",
    "\n",
    "                # Save IoU to file\n",
    "                with open(iou_path, \"w\") as f:\n",
    "                    f.write(f\"IoU: {iou_score:.4f}\")\n",
    "\n",
    "                all_step_results.append({\n",
    "                    \"step\": step + 1,\n",
    "                    \"segmentation_image\": step_best_segment,\n",
    "                    \"mask_image\": step_best_mask,\n",
    "                    \"ground_truth\": step_best_ground_truth\n",
    "                })\n",
    "\n",
    "        print(\"\\n=== Final Best Refined Prompt ===\")\n",
    "        print(current_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265e27c-c52f-41b8-ae6d-a3356a784fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
